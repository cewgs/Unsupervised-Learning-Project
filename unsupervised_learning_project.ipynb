{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cewgs/Unsupervised-Learning-Project/blob/main/unsupervised_learning_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run the following cell to clone the project repository and install required dependencies.\n",
        "After running this cell, all data files and notebooks will be available in the Colab environment"
      ],
      "metadata": {
        "id": "6f__I5tFGSut"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# clone repo if not already cloned and install dependency\n",
        "import os\n",
        "\n",
        "if not os.path.exists(\"Unsupervised-Learning-Project\"):\n",
        "    !git clone https://github.com/cewgs/Unsupervised-Learning-Project.git\n",
        "\n",
        "%cd Unsupervised-Learning-Project\n",
        "\n",
        "# Install required external library\n",
        "!pip install -q gower\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jMecynbBMt7I",
        "outputId": "62b81c35-1d02-4375-af4d-289eff381de7"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gower in /usr/local/lib/python3.12/dist-packages (0.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from gower) (2.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from gower) (1.16.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "5_4lwOgFT05b"
      },
      "outputs": [],
      "source": [
        "# Imports\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
        "from sklearn.cluster import KMeans, AgglomerativeClustering\n",
        "from sklearn.metrics import silhouette_score, davies_bouldin_score, calinski_harabasz_score\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.mixture import GaussianMixture\n",
        "from sklearn.decomposition import PCA\n",
        "from scipy.cluster.hierarchy import dendrogram, linkage\n",
        "from sklearn.manifold import TSNE\n",
        "import gower\n",
        "from scipy.stats import chi2_contingency\n",
        "import random\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OAUNmFQXRzyk"
      },
      "source": [
        "#### Survey Data from 2017-2021"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "CvFj8szyW2w1"
      },
      "outputs": [],
      "source": [
        "data_frames = []\n",
        "\n",
        "data_paths = [\n",
        "\n",
        "   'Survey Data/2017.csv',\n",
        "   'Survey Data/2018.csv',\n",
        "   'Survey Data/2019.csv',\n",
        "   'Survey Data/2020.csv',\n",
        "   'Survey Data/2021.csv',\n",
        "]\n",
        "\n",
        "col_renames = {\n",
        "    '*Are you self-employed?*': 'self_employed',\n",
        "    '<strong>Are you self-employed?</strong>': 'self_employed',\n",
        "    'Is your employer primarily a tech company/organization?': 'tech_company',\n",
        "    'Is your primary role within your company related to tech/IT?': 'tech_related_role',\n",
        "    'Does your employer provide mental health benefitsÂ as part of healthcare coverage?': 'benefits',\n",
        "    'Does your employer provide mental health benefits as part of healthcare coverage?': 'benefits',\n",
        "    'Does your employer offer resources to learn more about mental health disorders and options for seeking help?': 'workplace_resources',\n",
        "    'Have you ever discussed your mental health with your employer?': 'mh_employer_discussion',\n",
        "    'Have you ever discussed your mental health with coworkers?': 'mh_coworker_discussion',\n",
        "    'Do you have medical coverage (private insurance or state-provided) that includes treatment of mental health disorders?': 'medical_coverage',\n",
        "    'Do you currently have a mental health disorder?': 'mental_health',\n",
        "    'Do you *currently* have a mental health disorder?': 'mental_health',\n",
        "    'Do you *currently* have a mental health disorder?': 'mental_health',\n",
        "    'How willing would you be to share with friends and family that you have a mental illness?': 'mh_share',\n",
        "    'What is your age?': 'age',\n",
        "    'What is your gender?': 'gender',\n",
        "    'What country do you *live* in?': 'country',\n",
        "    'What country do you <strong>live</strong> in?': 'country',\n",
        "    'Does your employer provide mental health benefits as part of healthcare coverage?\t': 'benefits',\n",
        "}\n",
        "\n",
        "col_to_keep = col_renames.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "0bboB4Y4XBYW",
        "outputId": "eca10d58-20db-4304-d806-47b863a114bb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Reading file:  Survey Data/2017.csv\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'Survey Data/2017.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3521622579.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_paths\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nReading file: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m   \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Shape - default: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Survey Data/2017.csv'"
          ]
        }
      ],
      "source": [
        "# Importing the files\n",
        "for path in data_paths:\n",
        "  print(\"\\nReading file: \", path)\n",
        "  df = pd.read_csv(path)\n",
        "  print('Shape - default: ', df.shape)\n",
        "\n",
        "  # Dropping columns > 90% missing values\n",
        "  max_na_filter = (0.9 * len(df))\n",
        "  df = df.loc[:,(df.isnull().sum(axis = 0) <= max_na_filter)]\n",
        "  print('Shape filtered: ', df.shape)\n",
        "\n",
        "  col_to_drop = [item for item in df.columns if item not in col_to_keep]\n",
        "  df.drop(columns = col_to_drop, inplace = True, errors = 'ignore')\n",
        "  print('Shape of column filtered: ', df.shape)\n",
        "\n",
        "  # Renaming columns across the datasets\n",
        "  df.drop(columns = col_to_drop, inplace = True, errors = 'ignore')\n",
        "  df.rename(columns = col_renames, inplace = True, errors = 'ignore')\n",
        "\n",
        "  data_frames.append(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t3urVbMgXBWA"
      },
      "outputs": [],
      "source": [
        "df = pd.concat(data_frames, ignore_index = True)\n",
        "print('combined data shape: ', df.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OApPxk8xM4MX"
      },
      "outputs": [],
      "source": [
        "# Overview\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# dtypes\n",
        "df.dtypes"
      ],
      "metadata": {
        "id": "5UJI1mw9nrQ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Cleaning"
      ],
      "metadata": {
        "id": "Pv12Kpn3grKj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FQrOOhmEM4Ka"
      },
      "outputs": [],
      "source": [
        "# number of missing values\n",
        "display(df.isna().sum().sort_values())\n",
        "display(print(\"df shape:\", df.shape))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Tech related roles\n",
        "reduce the dataset to tech related roles\n",
        "In this merged dataset we dont have the exact roles for each employee. So we drop rows with missing values. Some other surveys did include the exact roles which would allow to impute the column \"tech_related_role\". Further, this dataset only contains employed, not self-employed."
      ],
      "metadata": {
        "id": "cq5UfBRehJQr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LCoj8PZOwYKj"
      },
      "outputs": [],
      "source": [
        "# drop missing values in tech_related_role\n",
        "df = df[df['tech_related_role'].notna()]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['tech_related_role'].value_counts()"
      ],
      "metadata": {
        "id": "RC5QXkpnf5T_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#remove non tech related roles\n",
        "df.drop(df[df['tech_related_role'] == 0.0].index, inplace = True) # only tech roles remain\n",
        "\n",
        "# drop the column 'tech_related_roles'\n",
        "df.drop(columns = 'tech_related_role', inplace = True)\n"
      ],
      "metadata": {
        "id": "DvSYNqN0fnH7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Mental Health"
      ],
      "metadata": {
        "id": "sVNQZS6hBvRZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "display(df.isna().sum().sort_values())"
      ],
      "metadata": {
        "id": "SZSsp1qtBN5X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"mental_health\"].value_counts()"
      ],
      "metadata": {
        "id": "g0giSMPGA6ge"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Gender"
      ],
      "metadata": {
        "id": "j-DkV_NXzOLZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['gender'].value_counts()"
      ],
      "metadata": {
        "id": "LObzimEahdBK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# marking 25 missing values as \"others\"\n",
        "df['gender'] = df['gender'].fillna('Other')\n",
        "\n",
        "# format the records e.g. male/ Male\n",
        "df['gender'] = df['gender'].str.lower().str.strip()"
      ],
      "metadata": {
        "id": "CbTiPQEhzoWM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# group different genders into male, female, other\n",
        "\n",
        "gender_male = ['male', 'm', 'man', 'male/he/him', 'let\\'s keep it simple and say \\\"male\\\"', 'mostly male', 'masculine', 'identify as male', 'masculino', 'cishet male', 'cis male', 'mail', 'male-ish', 'cis-male', 'male (cis)', 'cis hetero male', 'dude', 'cisgender male', 'male, born with xy chromosoms', 'swm', 'ostensibly male']\n",
        "gender_female = ['female', 'f', 'woman', 'female, she/her', 'femile', 'female (cis)', 'f, cisgender', 'cisgendered woman', 'femmina', 'cis female', 'cis woman', 'cis-female', 'genderqueer demigirl', 'female (cisgender)', 'my sex is female.', 'femail', 'femalw', 'nonbinary/femme', 'cisgender female', 'she/her/they/them', '*shrug emoji* (f)',  'female/gender non-binary.', 'i identify as female']\n",
        "gender_other = ['agender', 'nonbinary', 'nb', 'b', '43','non-binary and gender fluid', 'gender non-conforming woman','cis-het male', 'demiguy', 'trans non-binary/genderfluid', 'other', 'afab non-binary', 'sometimes', 'questioning', 'none', 'trans man', 'trans woman', 'trans female', 'non-binary/agender', 'make', 'agender trans woman', 'transfeminine', '\\-', 'genderqueer/non-binary', 'non binary', 'contextual', 'agender/genderfluid', 'non-binary', 'genderfluid', 'god king of the valajar', 'uhhhhhhhhh fem genderqueer?', 'transgender', 'genderqueer', 'homem cis']\n",
        "\n",
        "# transform gender in simpler form\n",
        "df['gender'] = df['gender'].replace(gender_male, 'Male')\n",
        "df['gender'] = df['gender'].replace(gender_female, 'Female')\n",
        "df['gender'] = df['gender'].replace(gender_other, 'Other')\n",
        "\n",
        "# lets check records now\n",
        "df['gender'].value_counts()\n",
        "\n"
      ],
      "metadata": {
        "id": "eCg03aD6hspl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### benefits"
      ],
      "metadata": {
        "id": "WMr4DdjjOBXE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# check missing values\n",
        "df.isna().sum().sort_values()"
      ],
      "metadata": {
        "id": "cDOg6KaWUXjd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['benefits'].value_counts()"
      ],
      "metadata": {
        "id": "-sOOG1XFOCTK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 'Not eligible for coverage / NA', equal to'No'\n",
        "\n",
        "df.loc[df['benefits'] == 'Not eligible for coverage / NA' , 'benefits'] = 'No'\n",
        "\n",
        "df['benefits'].value_counts()"
      ],
      "metadata": {
        "id": "SZjUAvoTOMEF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### workplace_resources"
      ],
      "metadata": {
        "id": "CSXe1Vwuq5gs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['workplace_resources'].value_counts()"
      ],
      "metadata": {
        "id": "GM8j2Cr9qugt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### mh_employer_discussion"
      ],
      "metadata": {
        "id": "uI_AgWl_x54r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['mh_employer_discussion'].value_counts()"
      ],
      "metadata": {
        "id": "s1IA8oSfx1FP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### mh_coworker_discussion"
      ],
      "metadata": {
        "id": "AYM9kZsn3uex"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['mh_coworker_discussion'].value_counts()"
      ],
      "metadata": {
        "id": "iZTLHLPa3fB5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RWSyLSH7K_kC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### medical_coverage"
      ],
      "metadata": {
        "id": "yyYRuWngVgrp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# check missing values\n",
        "df.isna().sum().sort_values()"
      ],
      "metadata": {
        "id": "9DYkOiZQVWG5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If the the employee has health benifits he should have medical coverage. Further we will use OECD (OECD-ilibrary.org) data to interpolate the coverage for certain countries."
      ],
      "metadata": {
        "id": "ZUIUzD1w591L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# medical coverage if the company is providing health benefits\n",
        "df.loc[df['benefits'] == 'Yes', 'medical_coverage'] = 'Yes'\n",
        "\n",
        "# Employees are covered (Uk, Germany, Canada, France, Spain, Netherlands)\n",
        "countries = ['UK', 'Germany', 'Canada', 'France', 'Spain', 'Netherlands']\n",
        "df.loc[(df['country'].isin(countries)), 'medical_coverage'] = 'Yes'\n",
        "\n",
        "# Lets check how many null values we have now\n",
        "df['medical_coverage'].isna().sum()\n"
      ],
      "metadata": {
        "id": "TcAMCil3Vtjr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# According to OECD, USA has 90% medical coverage\n",
        "total_us = df.loc[df['country'] == 'United States of America']\n",
        "no_coverage_us = df.loc[(df['medical_coverage'].isna()) & (df['country'] == 'United States of America')]\n",
        "\n",
        "print('US employed :{}'.format(len(total_us)))\n",
        "print('USA residents without medical coverage in df :{}'.format(len(no_coverage_us)))\n",
        "print('not insured: ' + str(round(100*((len(no_coverage_us)) / (len(total_us))), 2)) + '%')\n"
      ],
      "metadata": {
        "id": "jwPvIGtMaEme"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# According to the OECD data 90 % in the US should be insured.\n",
        "# we assign 95 more with insurance.\n",
        "\n",
        "no_coverage_us_list = list(no_coverage_us.index)\n",
        "\n",
        "sample = random.sample(no_coverage_us_list, 95) # assign randomly\n",
        "(sample.sort())\n",
        "\n",
        "df.loc[sample , 'medical_coverage'] = 'No'\n",
        "df.loc[(df['country'] == 'United States of America') & (df['medical_coverage'].isna()) , 'medical_coverage'] = 'Yes'\n",
        "\n",
        "df.isna().sum() / len(df)"
      ],
      "metadata": {
        "id": "QLxD3knD9Fy3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The remaining 14% will be dropped\n",
        "df.dropna(inplace = True)\n",
        "\n",
        "display(df.isna().sum())\n",
        "display(print(\"df shape:\", df.shape))\n"
      ],
      "metadata": {
        "id": "D4ZpujT5ffn3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### age"
      ],
      "metadata": {
        "id": "1OApQq7kgZtj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We can see outliers as min age is 0.\n",
        "df['age'].describe()"
      ],
      "metadata": {
        "id": "haiw75vVgFaD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# number of unique values per unqiue\n",
        "df['age'].value_counts()"
      ],
      "metadata": {
        "id": "Cr2-zpTGQUo4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# counts with age <= 18\n",
        "df[(df[\"age\"] <= 18)]"
      ],
      "metadata": {
        "id": "9IMBzHad967l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Age 0 outlier, drop  outside 21-55 to avoid too small clusters (single counts)\n",
        "# Drop rows where age <= 21 or age > 55\n",
        "df = df.drop(df[(df[\"age\"] < 20) | (df[\"age\"] > 55)].index)\n",
        "\n",
        "# Check summary statistics after dropping\n",
        "df['age'].describe()\n"
      ],
      "metadata": {
        "id": "uv0ZDx8-gZNm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### mh_share"
      ],
      "metadata": {
        "id": "T8ICAeyJAC0k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ranges from 0 - 10, ordinal\n",
        "df['mh_share']"
      ],
      "metadata": {
        "id": "tT_zYghP_3zs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### formatting"
      ],
      "metadata": {
        "id": "blFQNibrh61Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['self_employed'] = df['self_employed'].replace({1 : 'Yes' , 0 : 'No'})\n",
        "df['tech_company'] = df['tech_company'].replace({1.0 : 'Yes' , 0.0 : 'No'})\n",
        "df['mh_employer_discussion'] = df['mh_employer_discussion'].replace({1.0 : 'Yes' , 0.0 : 'No'})\n",
        "df['mh_coworker_discussion'] = df['mh_coworker_discussion'].replace({1.0 : 'Yes' , 0.0 : 'No'})"
      ],
      "metadata": {
        "id": "Rw6nKQmSit5o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### self_employed"
      ],
      "metadata": {
        "id": "Z_mWb_qAAQzm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#  no self-employed\n",
        "df.drop(columns = 'self_employed', inplace = True)"
      ],
      "metadata": {
        "id": "AE6BB8w_iJJS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Region"
      ],
      "metadata": {
        "id": "s5mse7NHeE9T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# countries\n",
        "df['country'].value_counts() / len(df)"
      ],
      "metadata": {
        "id": "ZOHispn7iZ-U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Keep only employers in the USA:\n",
        "df = df[df['country'] == 'United States of America']\n",
        "df.shape"
      ],
      "metadata": {
        "id": "KwluSNHQdz5r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Explorative Data Analysis (USA)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "OT1FrMZPlZZU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The scope of the explorative analysis are employers working and living in the US."
      ],
      "metadata": {
        "id": "gi5r7LHAeMl_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Age Distribution"
      ],
      "metadata": {
        "id": "_Bb1Y6ZrU8M8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# age distrbution\n",
        "sns.histplot(data=df, x='age', kde=True)\n",
        "plt.title('Age Distribution')\n",
        "plt.xlabel('Age')\n",
        "plt.ylabel('Frequency')\n",
        "\n",
        "mean_age = df['age'].mean()\n",
        "median_age = df['age'].median()\n",
        "std_age = df['age'].std()\n",
        "\n",
        "plt.text(0.7, 0.9, f'Mean: {mean_age:.2f}', transform=plt.gca().transAxes)\n",
        "plt.text(0.7, 0.85, f'Median: {median_age:.2f}', transform=plt.gca().transAxes)\n",
        "plt.text(0.7, 0.8, f'SD: {std_age:.2f}', transform=plt.gca().transAxes)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "01qOzlnaiM_N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Gender"
      ],
      "metadata": {
        "id": "YuGK_vdBS_X1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "colors = sns.color_palette('pastel')[0:5]\n",
        "df.groupby(['gender']).size().plot(kind = 'pie', autopct = '%1.1f%%',\n",
        "                                   label = 'Gender', colors = colors)"
      ],
      "metadata": {
        "id": "z-5BV9XBWTaM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Most of the samples come from the USA (80%). For explorative analysis we group the countries. The group \"others\" is a mix of various countries and not meaningful."
      ],
      "metadata": {
        "id": "d2-sfIPHiLAQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "# Group countries into 'Europe', 'United States', and 'Others'\n",
        "europe_countries = ['United Kingdom', 'Germany', 'Spain', 'France', 'Netherlands', 'Ireland', 'Switzerland', 'Estonia', 'Norway', 'Finland', 'Greece', 'Sweden', 'Poland', 'Portugal', 'Austria']\n",
        "\n",
        "def categorize_country(country):\n",
        "    if country == 'United States of America':\n",
        "        return 'United States'\n",
        "    elif country in europe_countries:\n",
        "        return 'Europe'\n",
        "    else:\n",
        "        return 'Others'\n",
        "\n",
        "df['country_group'] = df['country'].apply(categorize_country)\n",
        "\n",
        "# percentage of individuals with mental health issues within each country group\n",
        "mental_health_by_country_group = df.groupby('country_group')['mental_health'].value_counts(normalize=True).mul(100).unstack()\n",
        "\n",
        "display(mental_health_by_country_group)\n",
        "'''\n"
      ],
      "metadata": {
        "id": "Z4OEBb0Zewq2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Mental Health Status"
      ],
      "metadata": {
        "id": "LBMiQIcsch7K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mental Health Status overall\n",
        "df.groupby(['mental_health']).size().plot(kind='pie', autopct='%1.0f%%', label='Mental Health Issues', colors = colors)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "XXs1wjKDclSU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Mental Health Issues by Gender"
      ],
      "metadata": {
        "id": "1pqb-g-CTEID"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "male_with_mental_health = df[(df[\"mental_health\"] == 'Yes') & (df[\"gender\"] == 'Male')]\n",
        "female_with_mental_health = df[(df[\"mental_health\"] =='Yes') & (df[\"gender\"] == 'Female')]\n",
        "other_with_mental_health = df[(df[\"mental_health\"] =='Yes') & (df[\"gender\"] == 'Other')]\n",
        "\n",
        "sizes = [\n",
        "    male_with_mental_health['gender'].value_counts().get('Male', 0),\n",
        "    female_with_mental_health['gender'].value_counts().get('Female', 0),\n",
        "    other_with_mental_health['gender'].value_counts().get('Other', 0),\n",
        "]\n",
        "labels = ['Male', 'Female', 'Other']\n",
        "\n",
        "fig1, ax1 = plt.subplots()\n",
        "fig1.suptitle('Mental Health Issues by Gender', fontsize=16)\n",
        "ax1.pie(sizes, labels = labels, autopct = '%1.1f%%', colors = colors)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "U8FFxfNdG23e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Mental Health by Age and Gender"
      ],
      "metadata": {
        "id": "QXDeEchVhCuo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot by Age, Gender and Mental Health\n",
        "\n",
        "g = sns.FacetGrid(df, row = 'gender', col = 'mental_health', height = 4)\n",
        "g.map(plt.hist, 'age', bins = 10, alpha = 0.6)\n",
        "g.add_legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "qieow9ggibX7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Average/Median Age for Mental Health Status and Gender"
      ],
      "metadata": {
        "id": "MXrX3r3oXUgW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mean, median for each gender and their mental health status\n",
        "average_age_by_gender_and_mh = df.groupby(['gender', 'mental_health'])['age'].agg(['mean', 'median', 'count']).reset_index() # possible features later\n",
        "\n",
        "# Display the results\n",
        "display(average_age_by_gender_and_mh)"
      ],
      "metadata": {
        "id": "RuEeu2s5UEne"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Ressources/Benefits for Mental Health Issues\n"
      ],
      "metadata": {
        "id": "iCpqgSOMOthe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# health benefits provided by employer\n",
        "df.groupby(['benefits']).size().plot(kind = 'pie', autopct = '%1.1f%%', label = 'Health benefits provided ', colors = colors)"
      ],
      "metadata": {
        "id": "icsV6JcFQQf0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ressources for mental health provided by employer\n",
        "df.groupby(['workplace_resources']).size().plot(kind = 'pie', autopct = '%1.1f%%', label = 'Mental Health Resources Provided ', colors = colors)"
      ],
      "metadata": {
        "id": "3_JEjmcLrrAO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Following observations can be derived from above.\n",
        "\n",
        "- More than 60% employee have medical coverage provided from employer, but not the resources to get more information, suggesting that companies do not get active involvement.\n",
        "- Around 12% employee do not have medical coverage."
      ],
      "metadata": {
        "id": "Ytg3zsi4RKJJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Mental Health Discussion with Employer\n"
      ],
      "metadata": {
        "id": "jQXEkToURlqA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Discuss mental health with employer\n",
        "df.groupby(['mh_employer_discussion']).size().plot(kind = 'pie', autopct = '%1.1f%%', label = 'Discuss Mental Health with Employer ', colors = colors)"
      ],
      "metadata": {
        "id": "_Q2p-sxG2Jeh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Employees with mental health issue who discuss it with their employer\n",
        "male_has_mh_and_not_discussed = df[(df[\"mental_health\"] == 'Yes') & (df[\"gender\"] == 'Male') & (df[\"mh_employer_discussion\"] == 'Yes')]\n",
        "female_has_mh_and_not_discussed = df[(df[\"mental_health\"] =='Yes') & (df[\"gender\"] == 'Female') & (df[\"mh_employer_discussion\"] == 'Yes')]\n",
        "other_has_mh_and_not_discussed = df[(df[\"mental_health\"] =='Yes') & (df[\"gender\"] == 'Other') & (df[\"mh_employer_discussion\"] == 'Yes')]\n",
        "\n",
        "sizes = [\n",
        "    male_has_mh_and_not_discussed['gender'].value_counts().get('Male', 0),\n",
        "    female_has_mh_and_not_discussed['gender'].value_counts().get('Female', 0),\n",
        "    other_has_mh_and_not_discussed['gender'].value_counts().get('Other', 0),\n",
        "]\n",
        "labels = ['Male', 'Female', 'Other']\n",
        "\n",
        "fig1, ax1 = plt.subplots()\n",
        "fig1.suptitle('Having MH issues and discuss with employer', fontsize=16)\n",
        "ax1.pie(sizes, labels = labels, autopct = '%1.1f%%', colors = colors)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "vy7MOXYZSwLx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Mental Health Discussion with Coworkers"
      ],
      "metadata": {
        "id": "aSghv3iSbRB3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.groupby(['mh_coworker_discussion']).size().plot(kind = 'pie', autopct = '%1.1f%%', label = 'Discuss Mental Health with Co-Workers ', colors = colors)"
      ],
      "metadata": {
        "id": "gl-damNL2w1I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "male_has_mh_and_not_discussed = df[(df[\"mental_health\"] == 'Yes') & (df[\"gender\"] == 'Male') & (df[\"mh_coworker_discussion\"] == 'Yes')]\n",
        "female_has_mh_and_not_discussed = df[(df[\"mental_health\"] =='Yes') & (df[\"gender\"] == 'Female') & (df[\"mh_coworker_discussion\"] == 'Yes')]\n",
        "other_has_mh_and_not_discussed = df[(df[\"mental_health\"] =='Yes') & (df[\"gender\"] == 'Other') & (df[\"mh_coworker_discussion\"] == 'Yes')]\n",
        "\n",
        "sizes = [\n",
        "    male_has_mh_and_not_discussed['gender'].value_counts().get('Male', 0),\n",
        "    female_has_mh_and_not_discussed['gender'].value_counts().get('Female', 0),\n",
        "    other_has_mh_and_not_discussed['gender'].value_counts().get('Other', 0),\n",
        "]\n",
        "labels = ['Male', 'Female', 'Other']\n",
        "\n",
        "fig1, ax1 = plt.subplots()\n",
        "fig1.suptitle('Having MH issues and discuss it with coworkers', fontsize=16)\n",
        "ax1.pie(sizes, labels = labels, autopct = '%1.1f%%', colors = colors)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "PAJ2l-Ma5aP0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# cross-tabulation of mh_employer_discussion and mh_coworker_discussion\n",
        "discussion_comparison_table = pd.crosstab(df['mh_coworker_discussion'], df['mh_employer_discussion'])\n",
        "\n",
        "display(discussion_comparison_table)"
      ],
      "metadata": {
        "id": "dTAtTVOJ_wuO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Wllingness Sharing Mental Heatlh with Family/Friends"
      ],
      "metadata": {
        "id": "gKOvI9txSHZ4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the median of mh_share\n",
        "median_mh_share = df['mh_share'].median()\n",
        "print(f\"Median of mh_share: {median_mh_share}\")\n",
        "\n",
        "# Create a histogram of mh_share\n",
        "plt.hist(df['mh_share'], bins=22, color=\"skyblue\") # ordinal\n",
        "plt.title('Distribution of Willingness to Share Mental Health with Family/Friends')\n",
        "plt.xlabel('Willingness to Share (0-10)')\n",
        "plt.ylabel('Frequency')\n",
        "\n",
        "# Add a vertical line at the median\n",
        "plt.axvline(median_mh_share, color='red', linestyle='dashed', linewidth=2, label=f'Median: {median_mh_share:.2f}')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "eSsBwcJOQQdX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b478379d"
      },
      "source": [
        "# Share Mental Health with Family/Friends\n",
        "df['mh_share'].value_counts().plot(kind='pie', autopct='%1.1f%%', figsize=(5, 5), colors=sns.color_palette('pastel'))\n",
        "plt.title('Percentage to Share Mental Health with Family/Friends (0-10)')\n",
        "plt.ylabel('') # Remove default ylabel\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Feature Engineering\n",
        "\n"
      ],
      "metadata": {
        "id": "PtRTp7mpan3n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# dtypes\n",
        "df.dtypes"
      ],
      "metadata": {
        "id": "f9VMZdlPDbr5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Binary Encoding"
      ],
      "metadata": {
        "id": "qcl4nGmEIZ41"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# store unencoded\n",
        "df_raw = df.copy()\n"
      ],
      "metadata": {
        "id": "iUCuqg2eK7ga"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.nunique()"
      ],
      "metadata": {
        "id": "7IgoVcUkG00H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "binary_cols = ['tech_company','mh_employer_discussion','mh_coworker_discussion','medical_coverage']\n",
        "df[binary_cols] = df[binary_cols].replace({'Yes': 1, 'No': 0})"
      ],
      "metadata": {
        "id": "KbUS8wA3IZ9l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_copy_with_country = df.copy()\n",
        "df.drop(columns = ['country'], inplace = True)"
      ],
      "metadata": {
        "id": "j9_xha43PJoq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Binning Age"
      ],
      "metadata": {
        "id": "CPLpXtnEHnaj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Binning into age groups\n",
        "age_bins = [18, 25, 35, 45, 55]\n",
        "age_labels = ['18-24','25-34','35-44','45-55']\n",
        "df['age_groups'] = pd.cut(df['age'], bins=age_bins, labels=age_labels)"
      ],
      "metadata": {
        "id": "aVs1JGLEFUoG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Binning mh_share"
      ],
      "metadata": {
        "id": "6o_v3793Hrxg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# binning to low, medium, high\n",
        "mh_bins = [0, 3, 7, 10]\n",
        "mh_labels = ['low','medium','high']\n",
        "df['mh_share_group'] = pd.cut(df['mh_share'], bins=mh_bins, labels=mh_labels)\n"
      ],
      "metadata": {
        "id": "5Ix_4u8BHr3R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Interaction Feautures"
      ],
      "metadata": {
        "id": "I_iuDD_TDQOq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Age\n",
        "df['age_mh_share'] = df['age'] * df['mh_share']\n",
        "df['age_employer'] = df['age'] * df['mh_employer_discussion']\n",
        "df['age_coworker'] = df['age'] * df['mh_coworker_discussion']\n",
        "df['age_tech'] = df['age'] * df['tech_company']\n",
        "\n",
        "# medical coverage\n",
        "df['mh_share_employer'] = df['mh_share'] * df['mh_employer_discussion']\n",
        "df['mh_share_coworker'] = df['mh_share'] * df['mh_coworker_discussion']\n",
        "df['mh_share_medical'] = df['mh_share'] * df['medical_coverage']\n",
        "df['mh_share_tech'] = df['mh_share'] * df['tech_company']\n",
        "df['mh_share_benefits'] = df['mh_share'] * df['benefits']\n",
        "df['mh_share_resources'] = df['mh_share'] * df['workplace_resources']\n",
        "\n",
        "# workplace features\n",
        "df['mh_discussion_both'] = df['mh_employer_discussion'] * df['mh_coworker_discussion']\n",
        "\n",
        "# Tech company and medical coverage\n",
        "df['tech_medical'] = df['tech_company'] * df['medical_coverage']\n",
        "\n",
        "# Tech company and coworker discussion\n",
        "df['tech_mh_coworker'] = df['tech_company'] * df['mh_coworker_discussion']\n",
        "\n",
        "# aggregation\n",
        "# Total discussions\n",
        "df['mh_discussion_total'] = df['mh_employer_discussion'] + df['mh_coworker_discussion']\n",
        "\n",
        "# Any discussion flag\n",
        "df['mh_discussion_any'] = (df['mh_discussion_total'] > 0).astype(int)\n",
        "\n",
        "# Total resources\n",
        "df['num_perks'] = df['benefits'] + df['workplace_resources']\n",
        "\n",
        "# create binary features for specific columns\n",
        "df['benefits_binary'] = df['benefits'].apply(lambda x: 1 if x == 'Yes' else 'No')\n",
        "df['workplace_resources_binary'] = df['workplace_resources'].apply(lambda x: 1 if x == 'Yes' else 0)\n",
        "df['mental_health_binary'] = df['mental_health'].apply(lambda x: 1 if x == 'Yes' else 0)"
      ],
      "metadata": {
        "id": "rYZVhrf0awAg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.nunique()"
      ],
      "metadata": {
        "id": "x8jCWgs_F5K8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode 'Yes' and 'No' to 1 and 0 for new features\n",
        "cols_to_encode = ['benefits_binary','workplace_resources_binary', 'mental_health_binary']\n",
        "for col in cols_to_encode:\n",
        "    df[col] = df[col].replace({'Yes': 1, 'No': 0})\n",
        "\n",
        "df"
      ],
      "metadata": {
        "id": "rsGxHopfEao0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "38fYjUoFHE0A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### One-hot encoding"
      ],
      "metadata": {
        "id": "gWjBkSYKNDVs"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bca68f33"
      },
      "source": [
        "# Get categorical columns\n",
        "categorical_cols = df.select_dtypes(include='object').columns.tolist()\n",
        "\n",
        "print(\"Categorical columns:\", categorical_cols)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1 = df.copy()"
      ],
      "metadata": {
        "id": "uD5z5gKSv3eU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "one_hot_cols = ['benefits','workplace_resources','gender','mental_health','mh_share_group','age_groups','mh_share_benefits',# interaction features\n",
        "               'mh_share_resources','num_perks'] #,'country_group' without\n",
        "one_hot_cols2= ['benefits', 'workplace_resources', 'mental_health', 'gender','mh_share_group','age_groups'] # without interaction features\n",
        "\n",
        "encoded_cols = pd.get_dummies(df1[one_hot_cols], prefix=one_hot_cols, dtype=int)\n",
        "\n",
        "df2 = pd.concat([df1, encoded_cols], axis=1)\n",
        "df2.drop(columns=one_hot_cols, inplace=True)\n",
        "df2.head()"
      ],
      "metadata": {
        "id": "9Wik587VkKkh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Feature Selection"
      ],
      "metadata": {
        "id": "KCZsDB3yyXOE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# check unqiue values\n",
        "# we have some interaction features that will dominate in variance\n",
        "df.nunique()"
      ],
      "metadata": {
        "id": "OJU4thMUFuot"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chi-Square Test"
      ],
      "metadata": {
        "id": "2B19gK0vED19"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# categorical columns\n",
        "categorical_cols = df.select_dtypes(include='object').columns\n",
        "\n",
        "print(\"Chi-Square test:\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "# Perform Chi-Square test for each pair of categorical features\n",
        "for i in range(len(categorical_cols)):\n",
        "    for j in range(i + 1, len(categorical_cols)):\n",
        "        col1 = categorical_cols[i]\n",
        "        col2 = categorical_cols[j]\n",
        "\n",
        "        # Create a contingency table\n",
        "        contingency_table = pd.crosstab(df[col1], df[col2])\n",
        "\n",
        "        # Perform the Chi-Square test\n",
        "        chi2, p, dof, expected = chi2_contingency(contingency_table)\n",
        "\n",
        "        print(f\"Chi-Square test between '{col1}' and '{col2}':\")\n",
        "        print(f\"  Chi2 Statistic: {chi2:.4f}\")\n",
        "        print(f\"  P-value: {p:.4f}\")\n",
        "        print(f\"  Degrees of Freedom: {dof}\")\n",
        "        print(\"-\" * 30)"
      ],
      "metadata": {
        "id": "6fzsDlwCEEAr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Scaling"
      ],
      "metadata": {
        "id": "-128fQmYFAuW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Columns to scale with MinMax\n",
        "cols_to_scale = [\n",
        "    'mh_share', 'age', 'age_employer', 'age_coworker', 'age_tech',\n",
        "    'mh_share_employer', 'mh_share_coworker', 'mh_share_medical',\n",
        "    'age_mh_share', 'mh_share_tech', 'mh_discussion_total'\n",
        "]\n",
        "\n",
        "# Binary columns untouched\n",
        "binary_cols = [col for col in df.columns if df[col].nunique() == 2]\n",
        "\n",
        "# Columns for MinMax scaling\n",
        "cols_minmax = [col for col in cols_to_scale if col not in binary_cols]\n",
        "\n",
        "df_scaled = df2.copy()\n",
        "\n",
        "# MinMaxScaler\n",
        "minmax_scaler = MinMaxScaler()\n",
        "df_scaled[cols_minmax] = minmax_scaler.fit_transform(df_scaled[cols_minmax])\n",
        "\n",
        "print(\"Scaled DataFrame:\")\n",
        "display(df_scaled.head())\n"
      ],
      "metadata": {
        "id": "FJuDWiQktS8Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "15ad12db"
      },
      "source": [
        "#### Principal Component Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### PCA Scaled Data"
      ],
      "metadata": {
        "id": "jOFPfzAA2-Vk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# PCA on scaled data\n",
        "pca = PCA(n_components=2)\n",
        "X_pca = pca.fit_transform(df_scaled)\n",
        "\n",
        "# Create a new DataFrame with the PCA components\n",
        "X_pca_df = pd.DataFrame(data = X_pca, columns = ['pca_1', 'pca_2'])\n",
        "\n",
        "loadings = pd.DataFrame(pca.components_[0], index=df2.columns, columns=[\"PC1\"])\n",
        "display(loadings.sort_values(\"PC1\", key=abs, ascending=False))\n",
        "print(\"Explained variance ratio:\", pca.explained_variance_ratio_)\n"
      ],
      "metadata": {
        "id": "6sX4aOfCcqqH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### PCA not scaled"
      ],
      "metadata": {
        "id": "4QrS9Sis3EpD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# PCA on not scaled data (df2)\n",
        "pca = PCA(n_components=2)\n",
        "X_pca_ns = pca.fit_transform(df2)\n",
        "\n",
        "# Create a new DataFrame with the PCA components\n",
        "X_pca_unscaled = pd.DataFrame(data = X_pca, columns = ['pca_1', 'pca_2'])\n",
        "\n",
        "loadings = pd.DataFrame(pca.components_[0], index=df2.columns, columns=[\"PC1\"])\n",
        "display(loadings.sort_values(\"PC1\", key=abs, ascending=False))\n",
        "print(\"Explained variance ratio:\", pca.explained_variance_ratio_)"
      ],
      "metadata": {
        "id": "leVVBeMD3Eyd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**If the data is not scaled, the clusters are along age, mh_share (willingness to share with friends). In this case this also includes the interaction features based on these features. The scaled data doesnt provide robust clusters in euclidean space.**"
      ],
      "metadata": {
        "id": "Ts3yr6dz3dSt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Unsupervised Model"
      ],
      "metadata": {
        "id": "ZUezhCjyjNwC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### K-Means, Agglomerative Clustering w. PCA, no scaling"
      ],
      "metadata": {
        "id": "S6HV7JL6_2Kk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# KMeans\n",
        "df_ns = X_pca_ns\n",
        "wcss_kmeans_pca = []\n",
        "silhouette_scores_kmeans_pca = []\n",
        "for i in range(1, 11):\n",
        "    kmeans_pca = KMeans(n_clusters=i, init='k-means++', random_state=42, n_init=10)\n",
        "    kmeans_pca.fit(df_ns)\n",
        "    wcss_kmeans_pca.append(kmeans_pca.inertia_)\n",
        "    if i > 1:\n",
        "        score = silhouette_score(df_ns, kmeans_pca.labels_)\n",
        "        silhouette_scores_kmeans_pca.append(score)\n",
        "\n",
        "# Agglomerative Clustering\n",
        "silhouette_scores_agg_pca = []\n",
        "for n_clusters in range(2, 11):\n",
        "    agg_clustering_pca = AgglomerativeClustering(n_clusters=n_clusters)\n",
        "    labels_pca = agg_clustering_pca.fit_predict(df_ns)\n",
        "    score = silhouette_score(df_ns, labels_pca)\n",
        "    silhouette_scores_agg_pca.append(score)\n",
        "\n",
        "# Plotting Elbow Method for KMeans\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(range(1, 11), wcss_kmeans_pca, marker='o')\n",
        "plt.title('Elbow Method')\n",
        "plt.xlabel('Number of clusters')\n",
        "plt.ylabel('WCSS')\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# Plotting Silhouette Scores for clustering\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(range(2, 11), silhouette_scores_kmeans_pca, marker='o', label='KMeans')\n",
        "plt.plot(range(2, 11), silhouette_scores_agg_pca, marker='o', label='Agglomerative Clustering')\n",
        "plt.title('Silhouette Scores')\n",
        "plt.xlabel('Number of clusters')\n",
        "plt.ylabel('Silhouette Score')\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "yk4cz5n4Z2Xi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### K-Means & Agglomerative Clustering with PCA/Scaling"
      ],
      "metadata": {
        "id": "qHe5mErhAk_4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_pca_reduced = X_pca\n",
        "\n",
        "# KMeans on PCA reduced data\n",
        "wcss_kmeans_pca = []\n",
        "silhouette_scores_kmeans_pca = []\n",
        "davies_bouldin_scores_kmeans_pca = [] #  Davies-Bouldin\n",
        "calinski_harabasz_scores_kmeans_pca = [] #  Calinski-Harabasz\n",
        "\n",
        "K = range(2, 11) # Try a range of cluster numbers\n",
        "\n",
        "for num_clusters in K:\n",
        "    kmeans_pca = KMeans(n_clusters=num_clusters, init='k-means++', random_state=42, n_init=10)\n",
        "    kmeans_pca.fit(df_pca_reduced)\n",
        "    wcss_kmeans_pca.append(kmeans_pca.inertia_)\n",
        "\n",
        "    # Calculate evaluation metrics\n",
        "    labels = kmeans_pca.labels_\n",
        "    silhouette_scores_kmeans_pca.append(silhouette_score(df_pca_reduced, labels)) # Evaluate on df3\n",
        "    davies_bouldin_scores_kmeans_pca.append(davies_bouldin_score(df_pca_reduced, labels)) # Added DBI calculation\n",
        "    calinski_harabasz_scores_kmeans_pca.append(calinski_harabasz_score(df_pca_reduced, labels)) # Added CHI calculation\n",
        "\n",
        "\n",
        "# Fit KMeans with the chosen number of clusters\n",
        "# and store the labels in a variable accessible by other cells.\n",
        "chosen_k = 2 # You can change this based on your preferred number of clusters\n",
        "final_kmeans_model = KMeans(n_clusters=chosen_k, init='k-means++', random_state=42, n_init=10)\n",
        "final_kmeans_model.fit(df_pca_reduced)\n",
        "kmeans_cluster_labels = final_kmeans_model.labels_ # Store labels in a new variable\n",
        "\n",
        "\n",
        "# Agglomerative Clustering on PCA reduced data\n",
        "silhouette_scores_agg_pca = []\n",
        "davies_bouldin_scores_agg_pca = [] # Added Davies-Bouldin scores list\n",
        "calinski_harabasz_scores_agg_pca = [] # Added Calinski-Harabasz scores list\n",
        "\n",
        "for n_clusters in range(2, 11):\n",
        "    # Use 'euclidean' metric for Agglomerative Clustering on PCA reduced data (which is numerical)\n",
        "    agg_clustering_pca = AgglomerativeClustering(n_clusters=n_clusters, metric='euclidean', linkage='ward') # Using 'ward' linkage as it's common with Euclidean distance\n",
        "    labels_pca = agg_clustering_pca.fit_predict(df_pca_reduced) # Fit on df3\n",
        "\n",
        "    # Calculate evaluation metrics\n",
        "    silhouette_scores_agg_pca.append(silhouette_score(df_pca_reduced, labels_pca)) # Evaluate on df3\n",
        "    davies_bouldin_scores_agg_pca.append(davies_bouldin_score(df_pca_reduced, labels_pca)) # Added DBI calculation\n",
        "    calinski_harabasz_scores_agg_pca.append(calinski_harabasz_score(df_pca_reduced, labels_pca)) # Added CHI calculation\n",
        "\n",
        "\n",
        "# Print the scores for each model and number of clusters\n",
        "print(\"KMeans Clustering Scores:\") # Updated title\n",
        "for i, num_clusters in enumerate(K):\n",
        "    print(f\"Number of Clusters (k) = {num_clusters}:\")\n",
        "    print(f\"  WCSS: {wcss_kmeans_pca[i]:.2f}\")\n",
        "    if num_clusters > 1:\n",
        "        print(f\"  Silhouette Score: {silhouette_scores_kmeans_pca[i-1]:.4f}\") # Adjust index for scores starting from k=2\n",
        "        print(f\"  Davies-Bouldin Index: {davies_bouldin_scores_kmeans_pca[i-1]:.4f}\") # Adjust index\n",
        "        print(f\"  Calinski-Harabasz Index: {calinski_harabasz_scores_kmeans_pca[i-1]:.2f}\")\n",
        "    print(\"-\" * 20)\n",
        "\n",
        "print(\"\\nAgglomerative Hierarchical Clustering Scores:\") # Updated title\n",
        "for i, num_clusters in enumerate(range(2, 11)):\n",
        "     print(f\"Number of Clusters (k) = {num_clusters}:\")\n",
        "     print(f\"  Silhouette Score: {silhouette_scores_agg_pca[i]:.4f}\")\n",
        "     print(f\"  Davies-Bouldin Index: {davies_bouldin_scores_agg_pca[i]:.4f}\")\n",
        "     print(f\"  Calinski-Harabasz Index: {calinski_harabasz_scores_agg_pca[i]:.2f}\")\n",
        "     print(\"-\" * 20)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "B0hAs5o3cusx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "697639b4"
      },
      "source": [
        "#### K-Means Clusters (k=4, best model)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "kmeans_model_k4 = KMeans(n_clusters=4,\n",
        "                         init='k-means++',\n",
        "                         random_state=42,\n",
        "                         n_init=10)\n",
        "kmeans_model_k4.fit(X_pca)\n",
        "\n",
        "\n",
        "kmeans_labels_k4 = kmeans_model_k4.labels_\n",
        "\n",
        "print(\"KMeans model with k=4 fitted successfully on X_pca.\")\n",
        "print(\"Cluster labels are stored in the 'kmeans_labels_k4' variable.\")\n",
        "\n",
        "# Calculate evaluation metrics for k=4\n",
        "silhouette_avg = silhouette_score(X_pca, kmeans_labels_k4)\n",
        "davies_bouldin_avg = davies_bouldin_score(X_pca, kmeans_labels_k4)\n",
        "calinski_harabasz_avg = calinski_harabasz_score(X_pca, kmeans_labels_k4)\n",
        "\n",
        "# Print the scores for k=4\n",
        "print(f\"K-Means K = 4\")\n",
        "print(f\"  Silhouette Score: {silhouette_avg:.4f}\")\n",
        "print(f\"  Davies-Bouldin Index: {davies_bouldin_avg:.4f}\")\n",
        "print(f\"  Calinski-Harabasz Index: {calinski_harabasz_avg:.2f}\")"
      ],
      "metadata": {
        "id": "pbIqnNClRj0m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### T-SNE"
      ],
      "metadata": {
        "id": "GVSairQ12qPd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# t-SNE for dimensionality reduction\n",
        "tsne = TSNE(n_components=2,\n",
        "            perplexity=30,\n",
        "            learning_rate=200,\n",
        "            n_iter=1000,\n",
        "            random_state=42)\n",
        "\n",
        "tsne_components = tsne.fit_transform(X_pca)\n",
        "\n",
        "# Create a DataFrame for the t-SNE components and cluster labels\n",
        "tsne_df = pd.DataFrame(data=tsne_components, columns=['TSNE_1', 'TSNE_2'])\n",
        "tsne_df['Cluster'] = kmeans_labels_k4\n",
        "\n",
        "# Visualize the clusters using t-SNE\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.scatterplot(x='TSNE_1', y='TSNE_2', hue='Cluster', data=tsne_df, palette='viridis', legend='full')\n",
        "plt.title('t-SNE visualization of K-Means (k=4)')\n",
        "plt.xlabel('TSNE_1')\n",
        "plt.ylabel('TSNE_2')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "HJfPLoVi2U9t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### Cluster Analysis K-Means"
      ],
      "metadata": {
        "id": "bBmogqX84hvo"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "781a0f41"
      },
      "source": [
        "df_with_clusters = df.copy()\n",
        "df_with_clusters['KMeans Cluster'] = kmeans_labels_k4\n",
        "\n",
        "# numerical features by cluster\n",
        "numerical_features_to_analyze = ['age', 'mh_share']\n",
        "cluster_numerical_means = df_with_clusters.groupby('KMeans Cluster')[numerical_features_to_analyze].mean()\n",
        "\n",
        "# categorical features by cluster\n",
        "categorical_features_to_analyze = ['gender', 'mental_health', 'benefits', 'workplace_resources', 'mh_employer_discussion',\n",
        "                                   'mh_coworker_discussion', 'medical_coverage','age','tech_company','mental_health_binary',\n",
        "                                   'benefits_binary'] # ,'country_group' exluded\n",
        "\n",
        "# distribution\n",
        "cluster_categorical_distribution = {}\n",
        "for col in categorical_features_to_analyze:\n",
        "    # frequency and normalize\n",
        "    distribution = df_with_clusters.groupby('KMeans Cluster')[col].value_counts(normalize=True).mul(100).unstack(fill_value=0)\n",
        "    cluster_categorical_distribution[col] = distribution\n",
        "\n",
        "# numerical means\n",
        "cluster_summary_table = cluster_numerical_means.copy()\n",
        "\n",
        "# categorical distributions\n",
        "for col, distribution_df in cluster_categorical_distribution.items():\n",
        "    # Rename columns\n",
        "    distribution_df.columns = [f'{col}_{cat}' for cat in distribution_df.columns]\n",
        "\n",
        "    # summary table\n",
        "    cluster_summary_table = cluster_summary_table.join(distribution_df)\n",
        "\n",
        "\n",
        "print(\"Cluster Summary Table (Mean of Numerical Features and Percentage of Categorical Features):\")\n",
        "display(cluster_summary_table)\n",
        "\n",
        "\n",
        "\n",
        "for col in categorical_features_to_analyze:\n",
        "  plt.figure(figsize=(8, 5))\n",
        "  sns.countplot(data=df_with_clusters, x=col, hue='KMeans Cluster')\n",
        "  plt.title(f'Distribution of {col} by KMeans Cluster')\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Interpretable tables in the cluster table\n",
        "# binary percentage is 100.0\n",
        "columns_interpretation = [\"age\",\"gender_Male\",'gender_Female','gender_Other',\"mh_share\",'mental_health_Yes',\n",
        "                          'workplace_resources_Yes','benefits_Yes','tech_company_1', 'mh_coworker_discussion_1',\n",
        "                          'mh_employer_discussion_1','mental_health_Possibly','mental_health_No'] #,'country_group_United States','country_group_Europe' exluded\n",
        "cluster_summary_table[columns_interpretation]"
      ],
      "metadata": {
        "id": "SRmG4B7cHyAK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# feature importance\n",
        "feature_importance1 = cluster_summary_table.max() - cluster_summary_table.min()\n",
        "feature_importance1.sort_values(ascending=False)\n",
        "\n",
        "plt.figure(figsize=(40,8))\n",
        "sns.heatmap(cluster_summary_table, annot=True, cmap='coolwarm')\n",
        "plt.title(\"Cluster Centroids Heatmap\")\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "Wp6PpsaBdFq1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Agglomerative with Gower Distance (k=4)"
      ],
      "metadata": {
        "id": "E9aPDreEZjd_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Best Model: Agglomerative Clustering with Gower Distance\n",
        "\n",
        "\n",
        "# Compute Gower distance\n",
        "gower_dist = gower.gower_matrix(X_pca)\n",
        "\n",
        "# Agglomerative Clustering with k=4\n",
        "n_clusters = 4\n",
        "agg_clustering = AgglomerativeClustering(\n",
        "    n_clusters=n_clusters,\n",
        "    metric='precomputed',  #  distance matrix\n",
        "    linkage='average'\n",
        ")\n",
        "labels = agg_clustering.fit_predict(gower_dist)\n",
        "\n",
        "# evaluation metrics for k=4\n",
        "silhouette_avg = silhouette_score(gower_dist, labels, metric='precomputed')\n",
        "davies_bouldin_avg = davies_bouldin_score(X_pca, labels)\n",
        "calinski_harabasz_avg = calinski_harabasz_score(X_pca, labels)\n",
        "\n",
        "# scores for k=4\n",
        "print(f\"Agglomerative Hierarchical Clustering Scores (on Gower Distance) for k=4\")\n",
        "print(f\"  Silhouette Score: {silhouette_avg:.4f}\")\n",
        "print(f\"  Davies-Bouldin Index: {davies_bouldin_avg:.4f}\")\n",
        "print(f\"  Calinski-Harabasz Index: {calinski_harabasz_avg:.2f}\")"
      ],
      "metadata": {
        "id": "a77hsSFL2bcg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### Dendogram"
      ],
      "metadata": {
        "id": "m_4btHI_oJwo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "linked = linkage(gower_dist, 'average')\n",
        "\n",
        "# Plot the dendrogram\n",
        "plt.figure(figsize=(10, 7))\n",
        "dendrogram(linked,\n",
        "            orientation='top',\n",
        "            distance_sort='descending',\n",
        "            show_leaf_counts=True)\n",
        "plt.title('Agglomerative Hierarchical Clustering Dendrogram (Gower Distance)')\n",
        "plt.xlabel('Sample Index')\n",
        "plt.ylabel('Distance')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "M60mJvSFce80"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### T-SNE"
      ],
      "metadata": {
        "id": "jpvbsfWYoNCu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# t-SNE for dimensionality reduction\n",
        "tsne = TSNE(n_components=2,\n",
        "            perplexity=30,\n",
        "            learning_rate=200,\n",
        "            n_iter=1000,\n",
        "            random_state=42)\n",
        "\n",
        "tsne_components = tsne.fit_transform(X_pca)\n",
        "\n",
        "# DataFrame for the t-SNE components and cluster labels\n",
        "tsne_df = pd.DataFrame(data=tsne_components, columns=['TSNE_1', 'TSNE_2'])\n",
        "tsne_df['Cluster'] = labels\n",
        "\n",
        "# Visualize the clusters\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.scatterplot(x='TSNE_1', y='TSNE_2', hue='Cluster', data=tsne_df, palette='viridis', legend='full')\n",
        "plt.title('t-SNE visualization of Agglomerative Clustering (k=4)')\n",
        "plt.xlabel('TSNE_1')\n",
        "plt.ylabel('TSNE_2')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "GqzyfO--dSeW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### Cluster Analysis 2"
      ],
      "metadata": {
        "id": "KlO-aNNioVGK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "df_with_clusters2 = df.copy()\n",
        "df_with_clusters2['Agg_Cluster'] = labels\n",
        "\n",
        "# numerical features by cluster\n",
        "numerical_features_to_analyze = ['age', 'mh_share']\n",
        "cluster_numerical_means = df_with_clusters2.groupby('Agg_Cluster')[numerical_features_to_analyze].mean()\n",
        "\n",
        "# categorical features by cluster\n",
        "categorical_features_to_analyze = ['gender', 'mental_health', 'benefits', 'workplace_resources', 'mh_employer_discussion',\n",
        "                                   'mh_coworker_discussion', 'medical_coverage','age','tech_company','mental_health_binary',\n",
        "                                   'benefits_binary'] #,'country_group'\n",
        "\n",
        "# distribution\n",
        "cluster_categorical_distribution = {}\n",
        "for col in categorical_features_to_analyze:\n",
        "    # frequency and normalize\n",
        "    distribution = df_with_clusters2.groupby('Agg_Cluster')[col].value_counts(normalize=True).mul(100).unstack(fill_value=0)\n",
        "    cluster_categorical_distribution[col] = distribution\n",
        "\n",
        "# numerical means\n",
        "cluster_summary_table2 = cluster_numerical_means.copy()\n",
        "\n",
        "# categorical distributions to the table\n",
        "for col, distribution_df in cluster_categorical_distribution.items():\n",
        "    # Rename columns\n",
        "    distribution_df.columns = [f'{col}_{cat}' for cat in distribution_df.columns]\n",
        "\n",
        "    # summary table\n",
        "    cluster_summary_table2 = cluster_summary_table2.join(distribution_df)\n",
        "\n",
        "\n",
        "print(\"Cluster Summary Table 2 (Mean of Numerical Features and Percentage of Categorical Features):\")\n",
        "display(cluster_summary_table2)\n",
        "\n",
        "\n",
        "\n",
        "for col in categorical_features_to_analyze:\n",
        "  plt.figure(figsize=(8, 5))\n",
        "  sns.countplot(data=df_with_clusters2, x=col, hue='Agg_Cluster')\n",
        "  plt.title(f'Distribution of {col} by  Cluster')\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "1q0R7LssOYKN",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Interpretable tables in the cluster table\n",
        "# binary percentage is 100.0\n",
        "columns_interpretation = [\"age\",\"gender_Male\",'gender_Female','gender_Other',\"mh_share\",'mental_health_Yes',\n",
        "                          'workplace_resources_Yes','benefits_Yes','tech_company_1', 'mh_coworker_discussion_1',\n",
        "                          'mh_employer_discussion_1','mental_health_Possibly'] # ,'country_group_United States','country_group_Europe' exluded\n",
        "cluster_summary_table2[columns_interpretation]"
      ],
      "metadata": {
        "id": "JLIRcHiR5CMP"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "OAUNmFQXRzyk",
        "Pv12Kpn3grKj",
        "blFQNibrh61Y"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}